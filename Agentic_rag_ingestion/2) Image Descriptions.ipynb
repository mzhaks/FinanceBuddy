{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "## Image Descriptions with Gemini \n",
    "\n",
    "Generate detailed textual descriptions for extracted images using Gemini 2.5 Flash.\n",
    "\n",
    "**Prerequisites:**\n",
    "-  run the Docling Data extraction notebook to extract dir like markdown, images and tables\n",
    "- Google_Gemini API key set in .env file\n",
    "\n",
    "**Output:**\n",
    "- Markdown descriptions saved to `data/rag-data/images_desc/{company}/{document}/page_X.md`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "### Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from pathlib import Path\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import base64\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "IMAGES_DIR = \"data/rag-data/images\"\n",
    "OUTPUT_DESC_DIR = \"data/rag-data/images_desc\"\n",
    "\n",
    "# Model configuration\n",
    "MODEL_NAME = \"gemini-2.5-flash\"\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "### Description Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "390882bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_image_prompt = \"\"\"Analyze this financial document page and extract meaningful data in a concise format.\n",
    "\n",
    "For charts and graphs:\n",
    "- Identify the metric being measured\n",
    "- List key data points and values\n",
    "- Note significant trends (growth, decline, stability)\n",
    "\n",
    "For tables:\n",
    "- Extract column headers and key rows\n",
    "- Note important values and totals\n",
    "\n",
    "For text:\n",
    "- Summarize key facts and numbers only\n",
    "- Skip formatting, headers, and navigation elements\n",
    "\n",
    "Be direct and factual. Focus on numbers, trends, and insights that would be useful for retrieval.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baf6e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import SystemMessage\n",
    "\n",
    "\n",
    "def generate_image_description(image_path: Path):\n",
    "    image = Image.open(image_path)\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format='PNG')\n",
    "\n",
    "    image_base64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "\n",
    "    message = HumanMessage(\n",
    "        content=[\n",
    "            {'type': 'text', 'text': describe_image_prompt},\n",
    "            {'type': 'image_url', 'image_url': f\"data:image/png;base64,{image_base64}\"}\n",
    "        ]\n",
    "    )\n",
    "    system_prompt = SystemMessage('You are an AI Assistant')\n",
    "\n",
    "    response = model.invoke([system_prompt, message])\n",
    "\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = Path(r'data\\rag-data\\images\\meta\\meta 10-k 2024\\page_64.png')\n",
    "\n",
    "response = generate_image_description(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(response)\n",
    "\n",
    "def generate_and_save_description(image_path: Path):\n",
    "    company_name = image_path.parent.parent.name\n",
    "    doc_name = image_path.parent.name\n",
    "\n",
    "    output_dir = Path(OUTPUT_DESC_DIR)/company_name/doc_name\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    desc_file = output_dir / f\"{image_path.stem}.md\"\n",
    "\n",
    "    if desc_file.exists():\n",
    "        return False\n",
    "    \n",
    "    description = generate_image_description(image_path)\n",
    "    desc_file.write_text(description, encoding='utf-8')\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec71f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = Path(r'data\\rag-data\\images\\meta\\meta 10-k 2024\\page_64.png')\n",
    "\n",
    "response = generate_and_save_description(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1fed772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [15:34<00:00, 12.13s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "images_path = Path(IMAGES_DIR)\n",
    "image_files = list(images_path.rglob(\"page_*.png\"))\n",
    "\n",
    "for image_path in tqdm(image_files):\n",
    "    response = generate_and_save_description(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc25e06d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
